DELETE FROM papers WHERE journal='P' AND volume='41' AND issue='5'; 

INSERT into papers (paperid,journal,year,volume,issue,start_page,end_page,ptype,title,abstract)
VALUES
('p4105rvw','P','2012','41','5',
'626','630','3',
'Reviews',
'Graham on A J Hudson: <i>The evolution of the eye from algae and jellyfish to humans: how vision adapts to environment</i>
<br/>
 Boston, MacLeod on Konderink: <i>Color for the sciences</i>
'
);

INSERT into papers (paperid,journal,year,volume,issue,start_page,end_page,ptype,title,abstract)
VALUES
('p7223','P','2012','41','5',
'606','619','0',
'The nature and origin of cross-modal associations to odours',
'Several studies have demonstrated reliable cross-modal associations between odours and
various visual, auditory, taste, and somatosensory attributes. How these associations arise is not well
understood. We examined whether cross-modal associations to odours themselves form distinct groups,
and whether these groupings relate to semantic (nameability, familiarity) and perceptual (intensity,
irritancy, and hedonics) olfactory attributes. Participants evaluated 20 odours, varying in all of the
latter attributes, and reported their visual, auditory, gustatory, and somatosensory associations for
each. Signifi cant inter-rater agreement was observed for all modalities except audition, and responses
in all modalities were consistent with those obtained on a repeat test session 2 weeks later. Two
groups of cross-modal odour associates emerged: one of which was related to the semantic attributes
of odours and another which related to their perceptual attributes. The exception was taste, which
was signifi cantly associated with both. While these results suggest that both semantic and perceptual
mechanisms underpin odour cross-modal matches, the data also point to the importance of hedonics
as a further contributing mechanism.
<br>

        <b>Keywords:</b> odour, cross-modal associations, somatosensory, colour, audition, taste, olfaction'
);


INSERT into papers (paperid,journal,year,volume,issue,start_page,end_page,ptype,title,abstract)
VALUES
('p7048','P','2012','41','5',
'517','531','0',
'Attentional capture without awareness in complex visual tasks',
'
Abrupt onsets of visual cues capture an observer’s attention, even when the cues do not reach
the observer’s visual awareness. In the present study, we investigated the effects of subthreshold cues
on the performance of a useful field of view task. Participants localized a target stimulus presented in
the peripheral visual field while identifying a character presented at the fovea. Before the presentation
of central and peripheral targets, a suprathreshold or subthreshold cue indicating a likely location of
the peripheral target was presented. We found that the suprathreshold cue led to both a benefit in the
valid trials and cost in the invalid trials, while the subthreshold cue produced only a benefit in the valid
trials without a cost in the invalid trials. Similar patterns of results were also observed when the cue
preceded the targets by 10–200 ms, although a small cost was observed for the 12 deg eccentricity at the
stimulus onset asynchronies of 50 ms and 100 ms in the subthreshold condition. These results indicate
that attentional capture occurs without awareness of the cue and suggest that the effect of the cue on the
spatial shift of attention would be different between the suprathreshold and subthreshold conditions.
<br>
        <b>Keywords:</b> attention, awareness, cueing, useful field of view task'
);
INSERT into papers (paperid,misc,journal,year,volume,issue,start_page,end_page,ptype,title,abstract)
VALUES
('p7052','Supplementary figures','P','2012','41','5',
'532','555','0',
'The identification of unfolding facial expressions',
'We asked whether the identification of emotional facial expressions (FEs) involves the simultaneous perception of the facial configuration or the detection of emotion-specific diagnostic cues. We recorded at high speed (500 frames s) the unfolding of the FE in five actors, each expressing six emotions (anger, surprise, happiness, disgust, fear, sadness). Recordings were coded every 10 frames (20&#160;ms of real time) with the Facial Action Coding System (FACS, Ekman et al 2002, Salt Lake City, UT: Research Nexus eBook) to identify the facial actions contributing to each expression, and their intensity changes over time. Recordings were shown in slow motion (1/20 of recording speed) to one hundred observers in a forced-choice identification task. Participants were asked to identify the emotion during the presentation as soon as they felt confident to do so. Responses were recorded along with the associated response times (RTs). The RT probability density functions for both correct and incorrect responses were correlated with the facial activity during the presentation. There were systematic correlations between facial activities, response probabilities, and RT peaks, and significant differences in RT distributions for correct and incorrect answers. The results show that a reliable response is possible long before the full FE configuration is reached. This suggests that identification is reached by integrating in time individual diagnostic facial actions, and does not require perceiving the full apex configuration.
      <br>

        <b>Keywords:</b> facial expressions, identification, action units, emotions'
);

INSERT into papers (paperid,journal,year,volume,issue,start_page,end_page,ptype,title,abstract)
VALUES
('p7096','P','2012','41','5',
'556','568','0',
'Experience produces the atypicality bias in object perception',
'When a morph face is produced with equal physical contributions from a typical parent face and an atypical parent face, the morph is judged to be more similar to the atypical parent. This discontinuity between physical and perceptual distance relationships, called the &#8220;atypicality bias&#8221; (Tanaka et&#160;al 1998,   199&#8211;220), has also been demonstrated with non-face objects (birds&#160;and cars; Tanaka and Corneille 2007   619&#8211;627). We tested whether the atypicality bias can be induced for a novel set of artificial objects. Two categories of &#8220;blob&#8221; stimuli were generated, each composed of typical and atypical members. Morphs averaged from typical and atypical parent exemplars were used to test the presence of an atypicality bias before and after participants were familiarized with blob items. In experiment 1, participants were trained to&#160;discriminate between the two blob categories. An atypicality bias was evident after, but not prior to, category training. In experiment 2, participants rated the pleasantness of the blobs instead of learning to categorize them; an atypicality bias was present only after the ratings task. This finding suggests that relatively passive exposure to exemplars is sufficient to influence perceptions of similarity, and that the atypicality bias is a manifestation of this influence.
      <br>'
);
INSERT into papers (paperid,journal,year,volume,issue,start_page,end_page,ptype,title,abstract)
VALUES
('p7124','P','2012','41','5',
'623','625','16',
'Payoff changes sensitivity by modulating the processing style',
'In a perceptual decision-making task, we compared a neutral payoff and two asymmetric payoffs: a liberal one, favouring positive responses, and a conservative one, favouring negative responses. Participants were presented with ambiguous images composed of superimposed target and non-target photographs, and asked to decide whether the target dominated in the picture. Signal-detection analysis demonstrated that the liberal payoff yielded significantly higher sensitivity than other payoffs. We argue that the liberal payoff encourages confirming the target&#8217;s domination, hence making it easier to ignore non-target elements of the picture. We conclude that payoff can influence perceptual decisions by changing the approach to the perceptual task, and how attention is allocated between different elements of the sensory input.
      <br>

        <b>Keywords:</b> signal detection, value, payoff, processing style, task performance'
);
INSERT into papers (paperid,journal,year,volume,issue,start_page,end_page,ptype,title,abstract)
VALUES
('p7128','P','2012','41','5',
'594','605','0',
'Forward masking of dynamic acoustic intensity: Effects of&#160;intensity region and end-level',
'Overestimation of loudness change typically occurs in response to up-ramp auditory stimuli (increasing intensity) relative to down-ramps (decreasing intensity) matched on frequency, duration, and end-level. In the experiment reported, forward masking is used to investigate a sensory component of up-ramp overestimation: persistence of excitation after stimulus presentation. White-noise and synthetic vowel 3.6&#160;s up-ramp and down-ramp maskers were presented over two regions of intensity change (40&#8211;60&#160;dB SPL, 60&#8211;80&#160;dB SPL). Three participants detected 10&#160;ms 1.5&#160;kHz pure tone signals presented at masker-offset to signal-offset delays of 10, 20, 30, 50, 90, 170&#160;ms. Masking magnitude was significantly greater in response to up-ramps compared with down-ramps for masker&#8211;signal delays up to and including 50&#160;ms. When controlling for an end-level recency bias (40&#8211;60&#160;dB SPL up-ramp vs 80&#8211;60&#160;dB SPL down-ramp), the difference in masking magnitude between up-ramps and down-ramps was not significant at each masker&#8211;signal delay. Greater sensory persistence in response to up-ramps is argued to have minimal effect on perceptual overestimation of loudness change when response biases are controlled. An explanation based on sensory adaptation is discussed.
      <br>

        <b>Keywords:</b> adaptation, auditory looming, intensity change, loudness, persistence'
);
INSERT into papers (paperid,journal,year,volume,issue,start_page,end_page,ptype,title,abstract)
VALUES
('p7176','P','2012','41','5',
'505','516','0',
'Contrasting predictions of low- and high-threshold models for the detection of changing visual features',
'Change blindness is the failure of observers to notice otherwise obvious changes to a visual
scene when those changes are masked in some way (eg by blotches or a blanking of the screen). Typically,
change blindness is taken as evidence that our representation of the visual world is capacity limited. The
locus of this capacity limit is thought to be visual short-term memory (vSTM). The capacity of vSTM
is usually estimated with a high-threshold model which assumes that each element in the stimulus
array is either fully encoded or not encoded at all, and, furthermore, that false alarms can arise only by
guessing, not by noise. Low-threshold models, by contrast, suggest that false alarms can arise by noise
at the level of detection/discrimination and/or decision. In this study, we use a well-controlled stimulus
display in which a single element changes over a blanking of the screen and contrast predictions from
a popular high-threshold model of vSTM with the predictions of a low-threshold model (specifically,
the sample-size model) of visual search and vSTM. The data were better predicted by the low-threshold
model.
<br>
<b>Keywords:</b> change blindness, visual search, vSTM, sample size'
);
INSERT into papers (paperid,misc,journal,year,volume,issue,start_page,end_page,ptype,title,abstract)
VALUES
('p7184','Supplementary figures','P','2012','41','5',
'577','593','0',
'Perceptually plausible sounds facilitate visually induced self-motion perception (vection)',
'We examined whether and how sounds influence visually induced illusory self-motion
(vection). Visual stimuli were presented for 40 s. They were made radially, expanding or contracting
visual motion field and luminance-defined gratings drifting in a vertical or horizontal direction.
Auditory stimuli were presented with the visual stimuli in most conditions; we employed sounds
that increased or decreased in intensity, or ascended or descended in frequency. As a result, the sound
which increased in intensity facilitated forward vection, and the sound which ascended/descended
in frequency facilitated upward/downward vection. The perceptual plausibility of the sound for the
corresponding self-motion seemed an important factor of enhancing vection.
'
);
INSERT into papers (paperid,misc,journal,year,volume,issue,start_page,end_page,ptype,title,abstract)
VALUES
('p7191','Supplementary figures','P','2012','41','5',
'569','576','0',
'Matching reality in the arts: Self-referential neural processing of naturalistic compared to surrealistic images',
'How are works of art that present scenes that match potential expectations processed in the brain, in contrast to such scenes that can never occur in real life because they would violate physical laws? Using functional magnetic resonance imaging, we investigated the processing of surrealistic and naturalistic images in visual artworks. Looking at naturalistic paintings leads to a significantly higher activation in the visual cortex and in the precuneus. Humans apparently own a sensitive mechanism even for artistic representations of the visual world to separate the impossible from what potentially matches physical reality. The observation reported here also suggests that sensory input corresponding to a realistic representation of the visual world elicits higher self-referential processing.
      <br>

        <b>Keywords:</b> perceptual identity, visual art, self-referential processing, cortical midline structures, reafference principle'
);
INSERT into papers (paperid,journal,year,volume,issue,start_page,end_page,ptype,title,abstract)
VALUES
('p7195','P','2012','41','5',
'620','622','16',
'Cross-sensory correspondences and naive conceptions of&#160;natural phenomena',
'Cross-sensory correspondences automatically intrude on performance in elaborate laboratory tasks (see Spence 2011   971&#8211;995, for a review). Outside such tasks, might they be responsible for some popular misconceptions about natural phenomena? Four simple demonstrations reveal how the correspondences between surface-lightness and weight, and between surface-lightness and auditory pitch, generate misconceptions about the weight and movement of objects and the vocalisations of animals. Specifically, people expect darker objects to be heavier than lighter-coloured objects, to free-fall more quickly, to roll across a table more slowly, and to make lower-pitched vocalisations when they come to life.
      <br>

        <b>Keywords:</b> correspondences, cross-sensory, conceptions of natural phenomena, naive science, object motion, surface lightness, pitch of vocalisation'
);
